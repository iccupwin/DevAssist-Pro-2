"""
–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è v3
–ü–æ–¥–¥–µ—Ä–∂–∫–∞ advanced extraction —Å —Ç–∞–±–ª–∏—Ü–∞–º–∏ –∏ –≤–∞–ª—é—Ç–∞–º–∏
"""
import logging
import asyncio
from typing import Dict, Any, List, Optional
from io import BytesIO
import json

# Document processing imports
import PyPDF2
import docx
import pdfplumber
import re

logger = logging.getLogger(__name__)

class V3DocumentProcessor:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self):
        self.currency_patterns = {
            'som': [
                r'(\d+(?:\s?\d{3})*(?:[,.]?\d{2})?)\s*(?:—Å–æ–º|som|KGS)',
                r'(?:—Å–æ–º|som|KGS)\s*(\d+(?:\s?\d{3})*(?:[,.]?\d{2})?)',
            ],
            'ruble': [
                r'(\d+(?:\s?\d{3})*(?:[,.]?\d{2})?)\s*(?:—Ä—É–±|rub|RUB|‚ÇΩ)',
                r'(?:—Ä—É–±|rub|RUB|‚ÇΩ)\s*(\d+(?:\s?\d{3})*(?:[,.]?\d{2})?)',
            ],
            'dollar': [
                r'\$(\d+(?:\s?\d{3})*(?:[,.]?\d{2})?)',
                r'(\d+(?:\s?\d{3})*(?:[,.]?\d{2})?)\s*(?:USD|dollar)',
            ],
            'euro': [
                r'‚Ç¨(\d+(?:\s?\d{3})*(?:[,.]?\d{2})?)',
                r'(\d+(?:\s?\d{3})*(?:[,.]?\d{2})?)\s*(?:EUR|euro)',
            ],
            'tenge': [
                r'(\d+(?:\s?\d{3})*(?:[,.]?\d{2})?)\s*(?:—Ç–µ–Ω–≥–µ|tenge|KZT)',
            ]
        }
    
    async def extract_advanced_content(self, file_content: bytes, filename: str) -> Dict[str, Any]:
        """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ç–∞–±–ª–∏—Ü –∏ –≤–∞–ª—é—Ç"""
        try:
            logger.info(f"üîç Starting advanced extraction for {filename}")
            
            extraction_result = {
                "text": "",
                "tables": [],
                "currencies": [],
                "structured_data": {},
                "metadata": {
                    "filename": filename,
                    "extraction_method": "v3_advanced",
                    "processing_timestamp": str(asyncio.get_event_loop().time())
                }
            }
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞ –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ
            file_ext = filename.lower().split('.')[-1]
            
            if file_ext == 'pdf':
                extraction_result = await self._process_pdf_advanced(file_content, extraction_result)
            elif file_ext in ['docx', 'doc']:
                extraction_result = await self._process_docx_advanced(file_content, extraction_result)
            elif file_ext == 'txt':
                extraction_result = await self._process_txt_advanced(file_content, extraction_result)
            else:
                # Fallback to basic text extraction
                extraction_result["text"] = file_content.decode('utf-8', errors='ignore')
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–∞–ª—é—Ç—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞
            extraction_result["currencies"] = self._extract_currencies(extraction_result["text"])
            
            # –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            extraction_result["structured_data"] = self._structure_financial_data(
                extraction_result["text"], 
                extraction_result["tables"],
                extraction_result["currencies"]
            )
            
            logger.info(f"‚úÖ Advanced extraction complete: {len(extraction_result['text'])} chars, {len(extraction_result['tables'])} tables, {len(extraction_result['currencies'])} currencies")
            
            return extraction_result
            
        except Exception as e:
            logger.error(f"‚ùå Advanced extraction error: {e}")
            # Fallback to basic extraction
            return {
                "text": file_content.decode('utf-8', errors='ignore'),
                "tables": [],
                "currencies": [],
                "structured_data": {},
                "metadata": {
                    "error": str(e),
                    "extraction_method": "fallback_basic"
                }
            }
    
    async def _process_pdf_advanced(self, file_content: bytes, result: Dict) -> Dict:
        """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ PDF —Å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º —Ç–∞–±–ª–∏—Ü"""
        try:
            # –ü–æ–ø—ã—Ç–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å pdfplumber –¥–ª—è –ª—É—á—à–µ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
            with pdfplumber.open(BytesIO(file_content)) as pdf:
                full_text = ""
                tables = []
                
                for page_num, page in enumerate(pdf.pages):
                    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
                    page_text = page.extract_text() or ""
                    full_text += page_text + "\n"
                    
                    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü
                    page_tables = page.extract_tables()
                    for table_idx, table in enumerate(page_tables or []):
                        if table and len(table) > 1:  # –í–∞–ª–∏–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
                            tables.append({
                                "page": page_num + 1,
                                "table_id": f"pdf_table_p{page_num}_{table_idx}",
                                "data": table,
                                "row_count": len(table),
                                "col_count": len(table[0]) if table else 0,
                                "extraction_method": "pdfplumber"
                            })
                
                result["text"] = full_text
                result["tables"] = tables
                
        except Exception as pdfplumber_error:
            logger.warning(f"‚ö†Ô∏è PDFPlumber failed, falling back to PyPDF2: {pdfplumber_error}")
            # Fallback to PyPDF2
            try:
                pdf_reader = PyPDF2.PdfReader(BytesIO(file_content))
                text = ""
                for page in pdf_reader.pages:
                    text += page.extract_text() + "\n"
                result["text"] = text
                result["metadata"]["fallback_used"] = "PyPDF2"
            except Exception as pypdf2_error:
                logger.error(f"‚ùå PyPDF2 also failed: {pypdf2_error}")
                result["text"] = "PDF extraction failed"
                result["metadata"]["error"] = str(pypdf2_error)
        
        return result
    
    async def _process_docx_advanced(self, file_content: bytes, result: Dict) -> Dict:
        """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ DOCX —Å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º —Ç–∞–±–ª–∏—Ü"""
        try:
            doc = docx.Document(BytesIO(file_content))
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤
            text = ""
            for paragraph in doc.paragraphs:
                text += paragraph.text + "\n"
            result["text"] = text
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü
            tables = []
            for table_idx, table in enumerate(doc.tables):
                table_data = []
                for row in table.rows:
                    row_data = [cell.text.strip() for cell in row.cells]
                    table_data.append(row_data)
                
                if table_data:
                    tables.append({
                        "table_id": f"docx_table_{table_idx}",
                        "data": table_data,
                        "row_count": len(table_data),
                        "col_count": len(table_data[0]) if table_data else 0,
                        "extraction_method": "python-docx"
                    })
            
            result["tables"] = tables
            
        except Exception as e:
            logger.error(f"‚ùå DOCX processing error: {e}")
            result["text"] = "DOCX extraction failed"
            result["metadata"]["error"] = str(e)
        
        return result
    
    async def _process_txt_advanced(self, file_content: bytes, result: Dict) -> Dict:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫–∏"""
        try:
            # –ü–æ–ø—ã—Ç–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ–¥–∏—Ä–æ–≤–∫—É
            import chardet
            detected = chardet.detect(file_content)
            encoding = detected.get('encoding', 'utf-8')
            confidence = detected.get('confidence', 0)
            
            logger.info(f"Detected encoding: {encoding} (confidence: {confidence:.2f})")
            
            # –î–µ–∫–æ–¥–∏—Ä—É–µ–º —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π
            text = file_content.decode(encoding, errors='ignore')
            result["text"] = text
            result["metadata"]["encoding"] = encoding
            result["metadata"]["encoding_confidence"] = confidence
            
        except Exception as e:
            logger.error(f"‚ùå TXT processing error: {e}")
            # Fallback to UTF-8
            result["text"] = file_content.decode('utf-8', errors='ignore')
            result["metadata"]["error"] = str(e)
        
        return result
    
    def _extract_currencies(self, text: str) -> List[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–∞–ª—é—Ç —Å —Å—É–º–º–∞–º–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        currencies = []
        
        for currency_type, pattern_list in self.currency_patterns.items():
            for pattern in pattern_list:
                matches = re.finditer(pattern, text, re.IGNORECASE)
                for match in matches:
                    amount_str = match.group(1)
                    # –û—á–∏—Å—Ç–∫–∞ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å—É–º–º—ã
                    amount_clean = re.sub(r'[^\d.,]', '', amount_str)
                    amount_clean = amount_clean.replace(',', '.')
                    
                    try:
                        amount = float(amount_clean)
                        currencies.append({
                            "currency": currency_type,
                            "amount": amount,
                            "formatted": f"{amount:,.2f}",
                            "original_text": match.group(0),
                            "position": match.start(),
                            "context": text[max(0, match.start()-50):match.end()+50]
                        })
                    except ValueError:
                        # –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å —á–∏—Å–ª–æ
                        continue
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –ø–æ–∑–∏—Ü–∏–∏ –≤ —Ç–µ–∫—Å—Ç–µ
        currencies.sort(key=lambda x: x["position"])
        
        return currencies
    
    def _structure_financial_data(self, text: str, tables: List[Dict], currencies: List[Dict]) -> Dict[str, Any]:
        """–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∏ —Ç–∞–±–ª–∏—Ü"""
        structured_data = {
            "budget_breakdown": {},
            "timeline_data": {},
            "team_structure": {},
            "technical_requirements": {},
            "currency_summary": {}
        }
        
        # –ê–Ω–∞–ª–∏–∑ —Ç–∞–±–ª–∏—Ü –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        for table in tables:
            table_data = table.get("data", [])
            if not table_data or len(table_data) < 2:
                continue
            
            headers = [str(cell).lower() if cell else "" for cell in table_data[0]]
            
            # –ü–æ–∏—Å–∫ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Ç–∞–±–ª–∏—Ü
            if any(keyword in " ".join(headers) for keyword in ["—Å—Ç–æ–∏–º–æ—Å—Ç—å", "—Ü–µ–Ω–∞", "–±—é–¥–∂–µ—Ç", "—Å—É–º–º–∞", "cost", "price"]):
                budget_data = {}
                for row in table_data[1:]:
                    if len(row) >= 2:
                        item = str(row[0]).strip()
                        amount_str = str(row[1]).strip()
                        
                        # –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                        amount_match = re.search(r'(\d+(?:\s?\d{3})*(?:[,.]?\d{2})?)', amount_str)
                        if amount_match:
                            try:
                                numeric_amount = float(amount_match.group(1).replace(' ', '').replace(',', '.'))
                                budget_data[item] = {
                                    "amount": numeric_amount,
                                    "formatted": f"{numeric_amount:,.2f}",
                                    "original": amount_str
                                }
                            except ValueError:
                                continue
                
                if budget_data:
                    structured_data["budget_breakdown"].update(budget_data)
        
        # –°—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∞–ª—é—Ç –ø–æ —Ç–∏–ø–∞–º
        currency_summary = {}
        for curr in currencies:
            curr_type = curr.get("currency", "unknown")
            if curr_type not in currency_summary:
                currency_summary[curr_type] = {
                    "count": 0,
                    "total_amount": 0,
                    "amounts": []
                }
            
            currency_summary[curr_type]["count"] += 1
            currency_summary[curr_type]["total_amount"] += curr.get("amount", 0)
            currency_summary[curr_type]["amounts"].append(curr.get("amount", 0))
        
        structured_data["currency_summary"] = currency_summary
        
        # –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ç–µ–∫—Å—Ç–∞
        timeline_keywords = ["—ç—Ç–∞–ø", "–º–µ—Å—è—Ü", "–Ω–µ–¥–µ–ª—è", "–¥–µ–Ω—å", "—Å—Ä–æ–∫", "deadline", "schedule"]
        timeline_matches = []
        for keyword in timeline_keywords:
            pattern = rf'{keyword}[:\s]*(\d+(?:\s?\d+)*)'
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                timeline_matches.append({
                    "keyword": keyword,
                    "value": match.group(1),
                    "context": text[max(0, match.start()-30):match.end()+30]
                })
        
        structured_data["timeline_data"] = {
            "matches": timeline_matches[:10],  # –ü–µ—Ä–≤—ã–µ 10 —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
            "total_matches": len(timeline_matches)
        }
        
        return structured_data