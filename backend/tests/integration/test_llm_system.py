#!/usr/bin/env python3
"""
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã LLM Service DevAssist Pro
–°–æ–≥–ª–∞—Å–Ω–æ –¢–ó –≠—Ç–∞–ø 4: AI Integrations
"""
import asyncio
import httpx
import json
import time
from typing import Dict, Any, Optional

class LLMSystemTest:
    def __init__(self, base_url: str = "http://localhost:8002", gateway_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.gateway_url = gateway_url

    async def test_llm_service_health(self) -> Dict[str, Any]:
        """–¢–µ—Å—Ç health check LLM Service"""
        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(f"{self.base_url}/health")
                return {
                    "status": "‚úÖ OK" if response.status_code == 200 else "‚ùå FAIL",
                    "response_code": response.status_code,
                    "response_time": f"{response.elapsed.total_seconds():.2f}s"
                }
        except Exception as e:
            return {
                "status": "‚ùå FAIL",
                "error": str(e)
            }

    async def run_all_tests(self):
        """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤ LLM —Å–∏—Å—Ç–µ–º—ã"""
        print("ü§ñ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ LLM Service DevAssist Pro...")
        
        health_result = await self.test_llm_service_health()
        print(f"Health check: {health_result['status']}")

async def main():
    test = LLMSystemTest()
    await test.run_all_tests()

if __name__ == "__main__":
    asyncio.run(main())